{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3596f2-a430-4cae-a918-578c00cfb7b4",
   "metadata": {},
   "source": [
    "## Pronouns and Perspective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c9ff994-9c79-47a2-9a7e-524c42dc01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "ALBUM_YEARS = {\n",
    "    # Lana Del Rey albums\n",
    "    \"aka_lizzy_grant\": 2010,\n",
    "    \"born_to_die\": 2012,\n",
    "    \"ultraviolence\": 2014,\n",
    "    \"honeymoon\": 2015,\n",
    "    \"lust_for_life\": 2017,\n",
    "    \"nfr\": 2019,\n",
    "    \"chemtrails_over_the_country_club\": 2021,\n",
    "    \"blue_banisters\": 2021,\n",
    "    \"did_you_know_ocean_blvd\": 2023,\n",
    "\n",
    "    # Non-Lana Albums\n",
    "    \"rumours\": 1977,\n",
    "    \"say_you_will\": 2003,\n",
    "    \"street_angel\": 1994,\n",
    "    \"badlands\": 2015,\n",
    "    \"hopeless_fountain_kingdom\": 2017,\n",
    "\n",
    "    # Poetry\n",
    "    \"ariel\": 1965,\n",
    "    \"violet_bent_backwards_over_the_grass\": 2020,\n",
    "    \"ocean_vuong_poetry\": 2019,\n",
    "    \"my_poetry\": 2025,\n",
    "    \"the_colossus\": 1960\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b799b527-f022-446b-a877-a11d130fb541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_type\n",
      "song    203\n",
      "poem     71\n",
      "Name: count, dtype: int64\n",
      "Song albums: ['aka_lizzy_grant', 'badlands', 'blue_banisters', 'born_to_die', 'chemtrails_over_the_country_club', 'did_you_know_ocean_blvd', 'honeymoon', 'hopeless_fountain_kingdom', 'lust_for_life', 'nfr', 'rumours', 'say_you_will', 'street_angel', 'ultraviolence']\n",
      "Poetry collections: ['ariel', 'my_poetry', 'ocean_vuong_poetry', 'the_colossus', 'violet_bent_backwards_over_the_grass']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Load the features table (adjust path if needed)\n",
    "df = pd.read_csv(\"../data/features/song_features.csv\")\n",
    "\n",
    "# 2) Define which \"albums\" are actually poetry collections\n",
    "POETRY_ALBUMS = {\n",
    "    \"ariel\",\n",
    "    \"violet_bent_backwards_over_the_grass\",\n",
    "    \"my_poetry\",\n",
    "    \"ocean_vuong_poetry\",\n",
    "    \"the_colossus\",\n",
    "}\n",
    "\n",
    "LANA_ALBUMS = {\n",
    "    \"aka_lizzy_grant\",\n",
    "    \"born_to_die\",\n",
    "    \"ultraviolence\",\n",
    "    \"honeymoon\",\n",
    "    \"lust_for_life\",\n",
    "    \"nfr\",\n",
    "    \"chemtrails_over_the_country_club\",\n",
    "    \"blue_banisters\",\n",
    "    \"did_you_know_ocean_blvd\",\n",
    "}\n",
    "\n",
    "NON_LANA_ALBUMS = {\n",
    "    \"rumours\",\n",
    "    \"say_you_will\",\n",
    "    \"street_angel\",\n",
    "    \"badlands\",\n",
    "    \"hopeless_fountain_kingdom\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 3) Ensure a text_type column exists (no KeyError ever again)\n",
    "df[\"text_type\"] = df[\"album\"].apply(lambda a: \"poem\" if a in POETRY_ALBUMS else \"song\")\n",
    "\n",
    "\n",
    "\n",
    "def classify_artist(album):\n",
    "    if album in LANA_ALBUMS:\n",
    "        return \"lana\"\n",
    "    elif album in NON_LANA_ALBUMS:\n",
    "        return \"non_lana\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "df[\"artist_group\"] = df[\"album\"].apply(classify_artist)\n",
    "\n",
    "df[\"year\"] = df[\"album\"].map(ALBUM_YEARS)\n",
    "df[[\"album\", \"year\"]].drop_duplicates().sort_values(\"year\")\n",
    "\n",
    "\n",
    "# 4) Clean splits you can reuse everywhere\n",
    "df_songs = df[df[\"text_type\"] == \"song\"].copy()\n",
    "df_poems = df[df[\"text_type\"] == \"poem\"].copy()\n",
    "\n",
    "df_lana = df_songs[df_songs[\"artist_group\"] == \"lana\"]\n",
    "df_non_lana = df_songs[df_songs[\"artist_group\"] == \"non_lana\"]\n",
    "\n",
    "\n",
    "\n",
    "# 5) Quick sanity checks (so you can trust it)\n",
    "print(df[\"text_type\"].value_counts())\n",
    "print(\"Song albums:\", sorted(df_songs[\"album\"].unique()))\n",
    "print(\"Poetry collections:\", sorted(df_poems[\"album\"].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf4039b-7a71-4136-b753-c42e09839138",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_PERSON = {\"i\", \"me\", \"my\", \"mine\", \"i'm\", \"i’ve\", \"i'll\"}\n",
    "SECOND_PERSON = {\"you\", \"your\", \"yours\", \"you’re\", \"you've\", \"you’ll\"}\n",
    "THIRD_PERSON = {\"he\", \"she\", \"they\", \"him\", \"her\", \"them\", \"his\", \"hers\", \"their\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe2f0fe-7598-4c40-bce2-11fbf3e5ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def pronoun_rates(text):\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "    total = len(tokens) if len(tokens) > 0 else 1\n",
    "\n",
    "    return {\n",
    "        \"first_person_rate\": sum(t in FIRST_PERSON for t in tokens) / total,\n",
    "        \"second_person_rate\": sum(t in SECOND_PERSON for t in tokens) / total,\n",
    "        \"third_person_rate\": sum(t in THIRD_PERSON for t in tokens) / total,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c3cc349-3951-44be-9ca5-f995ad5d39c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lexical_entropy', 'second_person_rate', 'repetition_rate',\n",
       "       'phonetic_entropy', 'phonetic_repetition_rate', 'album',\n",
       "       'first_person_rate', 'third_person_rate', 'song', 'line_end_similarity',\n",
       "       'text_type', 'artist_group', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a0fc1d-27d4-44be-8d4e-0dce0ba0a7d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lyrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'lyrics'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m pronoun_df = df.copy()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m rates = \u001b[43mpronoun_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlyrics\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.apply(pronoun_rates).apply(pd.Series)\n\u001b[32m      4\u001b[39m pronoun_df = pd.concat([pronoun_df, rates], axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'lyrics'"
     ]
    }
   ],
   "source": [
    "pronoun_df = df.copy()\n",
    "\n",
    "rates = pronoun_df[\"lyrics\"].apply(pronoun_rates).apply(pd.Series)\n",
    "pronoun_df = pd.concat([pronoun_df, rates], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d01d08-7ea7-4b1c-b8b8-a7a3b97c5fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "album_pronouns = (\n",
    "    pronoun_df\n",
    "    .groupby([\"artist_group\", \"album\"], as_index=False)\n",
    "    .agg({\n",
    "        \"first_person_rate\": \"mean\",\n",
    "        \"second_person_rate\": \"mean\",\n",
    "        \"third_person_rate\": \"mean\"\n",
    "    })\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff32d9-cb49-4478-a1de-aa5b84ebb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.5, 6))\n",
    "\n",
    "plt.scatter(\n",
    "    album_pronouns[\"first_person_rate\"],\n",
    "    album_pronouns[\"second_person_rate\"],\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "for _, row in album_pronouns.iterrows():\n",
    "    if row[\"artist_group\"] == \"lana\":\n",
    "        plt.text(\n",
    "            row[\"first_person_rate\"],\n",
    "            row[\"second_person_rate\"],\n",
    "            row[\"album\"],\n",
    "            fontsize=9,\n",
    "            weight=\"bold\"\n",
    "        )\n",
    "\n",
    "plt.xlabel(\"First-Person Rate (I / me)\")\n",
    "plt.ylabel(\"Second-Person Rate (you)\")\n",
    "plt.title(\"Perspective Space: Self vs Address\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d4f22-2f2b-486c-946c-8384b4336373",
   "metadata": {},
   "outputs": [],
   "source": [
    "lana_pronouns = (\n",
    "    album_pronouns[album_pronouns[\"artist_group\"] == \"lana\"]\n",
    "    .merge(df[[\"album\", \"year\"]].drop_duplicates(), on=\"album\")\n",
    "    .sort_values(\"year\")\n",
    ")\n",
    "\n",
    "for i in range(len(lana_pronouns) - 1):\n",
    "    x1, y1 = lana_pronouns.iloc[i][[\"first_person_rate\", \"second_person_rate\"]]\n",
    "    x2, y2 = lana_pronouns.iloc[i + 1][[\"first_person_rate\", \"second_person_rate\"]]\n",
    "\n",
    "    plt.annotate(\n",
    "        \"\",\n",
    "        xy=(x2, y2),\n",
    "        xytext=(x1, y1),\n",
    "        arrowprops=dict(arrowstyle=\"->\", linewidth=2)\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
